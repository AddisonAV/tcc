{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# !pip install PyIF\n",
    "# !pip install nose \n",
    "# !pip install numba\n",
    "from PyIF import te_compute as te\n",
    "from tabulate import tabulate\n",
    "\n",
    "from model.pytorch.dcrnn_supervisor import DCRNNSupervisor\n",
    "import yaml\n",
    "import pickle\n",
    "from lib.utils import load_graph_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_COVID_DataBase(_db, _group): \n",
    "    # Query the database to get the only a specific group of data    \n",
    "    filtered_db = _db.query(\"demographic_category == 'Age Group' and demographic_value == @_group\")\n",
    "\n",
    "\n",
    "    # drop columns that are not needed\n",
    "    filtered_db = filtered_db.drop(['demographic_category', 'demographic_value', 'percent_of_ca_population', 'report_date'], axis=1)\n",
    "#    filtered_db = pd.DataFrame(filtered_db.values.T, index=filtered_db.columns, columns=filtered_db.index)\n",
    "\n",
    "    return filtered_db"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Visual Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_graph_from_dataframe(data):\n",
    "  graph = nx.DiGraph()\n",
    "  data_values = data.values\n",
    "  \n",
    "  for row in range(0,len(data_values)): \n",
    "    for column in range(0,len(data_values)):\n",
    "      if data_values[row][column]: \n",
    "        graph.add_edge(row,column)\n",
    "  return graph\n",
    "\n",
    "def generate_graph_from_matrix(matrix):\n",
    "    gc_pvalues = pd.DataFrame(matrix)\n",
    "\n",
    "    threshold = 0.01\n",
    "    gc_boolean = gc_pvalues.applymap(lambda x: int(x<threshold))\n",
    "\n",
    "    graph = nx.DiGraph()\n",
    "\n",
    "    gen_graph = generate_graph_from_dataframe(gc_boolean)\n",
    "    nx.draw_circular(gen_graph, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_plot_graph_from_matrix(_matrix, _threshold, _title, _save=False, _filename='graph.png'):\n",
    "  plt.figure(figsize=(10,8))\n",
    "  _graph = nx.DiGraph()\n",
    "  pos = nx.spring_layout(_graph)\n",
    "\n",
    "  edges = []\n",
    "  for row in range(0,_matrix.shape[0]): \n",
    "    for column in range(0,_matrix.shape[1]):\n",
    "      if ((row != column) & (_matrix[row][column] > _threshold)):\n",
    "        #print(f'({column},{row}) = {round(_matrix[row][column],5)}')\n",
    "        edges.append((column,row,round(_matrix[row][column],5)))\n",
    "        _graph.add_edge(column, row, weight=round(_matrix[row][column],3))\n",
    "        #_graph.add_edge(column, row, color=column, width=(10*_matrix[row][column]), label=_matrix[row][column])\n",
    "  \n",
    "  pos = nx.circular_layout(_graph)\n",
    "  nx.draw(_graph, pos, with_labels=True, font_weight='bold')\n",
    "  edge_weight = nx.get_edge_attributes(_graph,'weight')\n",
    "  nx.draw_networkx_edge_labels(_graph, pos, label_pos=0.2, edge_labels=edge_weight)\n",
    "  plt.title(_title)\n",
    "  if _save:\n",
    "    plt.savefig(_filename, format=\"png\", dpi=300, bbox_inches='tight')\n",
    "  plt.show()\n",
    "\n",
    "  #print(f'\\nArestas (threshold = {_threshold}):\\n {edges}')\n",
    "\n",
    "  return _graph"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Granger Causality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the minimum pvalue in Granger Causality test result dictionary\n",
    "def find_min_pvalue(gc_result_dict):\n",
    "  min_pvalue = 1.0\n",
    "  for lag_key, lag_result in gc_result_dict.items():\n",
    "    #print(f'Lag: {lag_key}')    \n",
    "    \n",
    "    for test_key, test_result in lag_result[0].items():\n",
    "      if test_key != \"params_ftest\":\n",
    "        pvalue =  test_result[1]\n",
    "        if pvalue < min_pvalue:\n",
    "          min_pvalue = pvalue\n",
    "      \n",
    "  #print('\\n'f\"final p-value: {min_pvalue}\")\n",
    "  return min_pvalue\n",
    "\n",
    "\n",
    "def create_granger_matrix(dataset, max_lags=3):\n",
    "  matrix = []\n",
    "  noColumns = len(dataset.columns)\n",
    "  for i in range(0,noColumns):\n",
    "    row = []\n",
    "    for j in range(0,noColumns):\n",
    "      #print('\\n=======\\n'f'Checking if column {j} granger causes column {i}')\n",
    "      #calculate granger causality results\n",
    "      gc_ji_result = grangercausalitytests(dataset.iloc[:,[j,i]].values,max_lags, verbose=False)\n",
    "      #get p-value\n",
    "      #pvalue = gc_result[3][0]['lrtest'][1]\n",
    "      pvalue = find_min_pvalue(gc_ji_result)\n",
    "      #print (f\"pvalue: {pvalue}\")\n",
    "      #append pvalue in row\n",
    "      row.append(pvalue)\n",
    "    #append row in matrix\n",
    "    matrix.append(row)\n",
    "  #return matrix\n",
    "  return matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfer Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transfer_entropy_matrix(dataset):\n",
    "  matrix = []\n",
    "  noColumns = len(dataset.columns)\n",
    "  for i in range(0,noColumns):\n",
    "    row = []\n",
    "    for j in range(0,noColumns):\n",
    "      #print(f'Checking transfer entropy of column {j} towards column {i} \\n')\n",
    "      #calculate granger causality results\n",
    "      te_ji_result = te.te_compute(dataset.iloc[:,j].to_numpy(),dataset.iloc[:,i].to_numpy())\n",
    "      \n",
    "      #append pvalue in row\n",
    "      row.append(te_ji_result)\n",
    "\n",
    "    #append row in matrix\n",
    "    matrix.append(row)\n",
    "    \n",
    "  #return matrix\n",
    "  return matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_dataBase(_base, _causal, _lag):\n",
    "    # Create a new dataframe with with all zeros\n",
    "    # The new dataframe will have the same number of rows as the base dataframe minus Lag\n",
    "    _newDB = np.zeros((_base.shape[0] - _lag, _lag *2))\n",
    "    _Y = np.zeros((_base.shape[0] - _lag))\n",
    "    \n",
    "    # for every new row in the new dataframe\n",
    "    for i in range(0,_base.shape[0] - _lag):\n",
    "        # copy start to lag from the base dataframe\n",
    "        _newDB[i,0:_lag] = _base.iloc[i:i+_lag]\n",
    "        # copy lag to lag*2 causal from the causal dataframe\n",
    "        _newDB[i,_lag:_lag*2] = _causal.iloc[i:i+_lag]\n",
    "        # copy lag*2+1 from the base dataframe to last column value witch is the value to predict\n",
    "        _Y[i] = _base.iloc[i+_lag]\n",
    "\n",
    "    return _newDB, _Y\n",
    "\n",
    "\n",
    "# Code source: Jaques Grobler\n",
    "# License: BSD 3 clause\n",
    "def run_linear_regression_model(_X, _Y):\n",
    "    # Create linear regression object\n",
    "    regr = linear_model.LinearRegression()\n",
    "\n",
    "    # Train the model using the training sets\n",
    "    regr.fit(_X, _Y)\n",
    "\n",
    "    # Make predictions using the testing set\n",
    "    _y_pred = regr.predict(_X)\n",
    "\n",
    "    # Compute the error\n",
    "    _error =  _Y -_y_pred\n",
    "\n",
    "    return _error\n",
    "\n",
    "\n",
    "\n",
    "def causality_regression_model(dataset, _lag = 3):\n",
    "    matrix = np.zeros((dataset.shape[1],dataset.shape[1]))\n",
    "    #noColumns = len(dataset.columns)\n",
    "    # For every series in the train database\n",
    "    for bSeries in range(0, dataset.shape[1]):\n",
    "\n",
    "        # Create the base data with no casual influence\n",
    "        new_db, _y = format_dataBase(dataset[bSeries],  dataset[bSeries]*0, _lag)\n",
    "        \n",
    "        # Running the linear regression model on base data\n",
    "        base_error =  run_linear_regression_model(_X = new_db, _Y = _y)\n",
    "\n",
    "        # For every other series\n",
    "        for cSeries in range(0, dataset.shape[1]):\n",
    "            # Skip if the series is the same\n",
    "            if bSeries == cSeries:\n",
    "                continue\n",
    "\n",
    "            # Create the base data with causal influence\n",
    "            new_db, _y = format_dataBase(dataset[bSeries],  dataset[cSeries], _lag)\n",
    "\n",
    "            # Running the linear regression model on base data.\n",
    "            causal_error = run_linear_regression_model(_X = new_db, _Y = _y)\n",
    "\n",
    "            # Compute the error\n",
    "            error = (float (np.log(np.var(base_error)/ np.var(causal_error))) )\n",
    "            matrix[bSeries][cSeries] = error\n",
    "\n",
    "    return matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Table for comparison between causal results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comparison_database(_matrix_gran, _matrix_te, _matrix_ml):\n",
    "    _matrix = [{'index':'index','Granger': 'Granger','Transfer Entropy': 'Transfer Entropy','ML Regression': 'ML Regression'}]\n",
    "    for i in range(0, len(_matrix_gran)):\n",
    "        for j in range(0, len(_matrix_gran[i])):\n",
    "            _matrix += [{'index': f'{i} - {j}',\n",
    "                         'Granger': round(_matrix_gran[i][j], 5), \n",
    "                         'Transfer Entropy':  round(_matrix_te[i][j], 5), \n",
    "                         'ML Regression':  round(_matrix_ml[i][j], 5)}]\n",
    "\n",
    "    table = tabulate(_matrix, headers='firstrow', tablefmt='fancy_grid')\n",
    "    return table\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_dcrnn(adj_matrix):\n",
    "    with open('data/model/config.yaml') as f:\n",
    "        supervisor_config = yaml.load(f,Loader=yaml.Loader)\n",
    "\n",
    "\n",
    "        supervisor = DCRNNSupervisor(adj_mx=adj_matrix, **supervisor_config)\n",
    "        mean_score, outputs = supervisor.evaluate('test')\n",
    "        np.savez_compressed('data/dcrnn_predictions.npz', **outputs)\n",
    "        print(\"MAE : {}\".format(mean_score))\n",
    "        print('Predictions saved as {}.'.format('data/dcrnn_predictions.npz'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIAL CONFIGURATION\n",
    "with open('config.yaml') as f:\n",
    "    config = yaml.load(f,Loader=yaml.Loader)\n",
    "    in_db = pd.read_csv(config['base']['dataset_dir'])     # Input database\n",
    "    age_group = config['base']['age_group']                # Age group\n",
    "    AG_index = config['base']['age_group_index']           # Age group index (range 0-3)\n",
    "    save_figs = config['base']['save_figs']                # True to save the figures\n",
    "\n",
    "\n",
    "# Format the database\n",
    "formated_db = format_COVID_DataBase(in_db, age_group[AG_index])\n",
    "# Save the raw formated database\n",
    "formated_db = pd.DataFrame(formated_db, dtype=float)\n",
    "#save database into h5 file.\n",
    "formated_db.to_hdf('./data/covid-db.h5', key='df', mode='w')\n",
    "\n",
    "# # Prepare the train and test database\n",
    "# scaler = MinMaxScaler((-1,1))\n",
    "\n",
    "# # Fit database to scaler\n",
    "# scaler.fit(formated_db)\n",
    "\n",
    "# # Now apply the transformations to the data:\n",
    "# formated_db = scaler.transform(formated_db)\n",
    "\n",
    "\n",
    "# GRANGER CAUSALITY MATRIX\n",
    "theMatrix_gran = create_granger_matrix(formated_db, max_lags=3)\n",
    "#gen_graph_causality = generate_and_plot_graph_from_matrix(pd.DataFrame(theMatrix), 0, f'Granger Causality, age group ({age_group[AG_index]})',\n",
    "#                                                          save_figs, _filename=f'graphs/causality_graphs/{age_group[AG_index]}_granger.png')\n",
    "# Save to pickle file.\n",
    "theMatrix_gran = np.array(theMatrix_gran, dtype=np.float32)\n",
    "with open('./data/graph/gc_adj_mat.pkl', 'wb') as f:\n",
    "    pickle.dump([[], [], theMatrix_gran], f, protocol=2)\n",
    "\n",
    "# # TRANSFER ENTROPY MATRIX\n",
    "# theMatrix_te = create_transfer_entropy_matrix(pd.DataFrame(formated_db))\n",
    "# #gen_graph_te = generate_and_plot_graph_from_matrix(pd.DataFrame(theMatrix), 0, f'Transfer Entropy, age group ({age_group[AG_index]})',\n",
    "# #                                                   save_figs, _filename=f'graphs/causality_graphs/{age_group[AG_index]}_te.png')\n",
    "# # Save to pickle file.\n",
    "# theMatrix_te = np.array(theMatrix_te)\n",
    "# with open('./data/graph/te_adj_mat.pkl', 'wb') as f:\n",
    "#     pickle.dump([[], [], theMatrix_gran], f, protocol=2)\n",
    "\n",
    "\n",
    "# # ML MODEL MATRIX\n",
    "# theMatrix_ml = causality_regression_model(pd.DataFrame(formated_db))\n",
    "# #gen_graph_ml = generate_and_plot_graph_from_matrix(pd.DataFrame(theMatrix), 0, f'ML Model, age group ({age_group[AG_index]})',\n",
    "# #                                                   save_figs, _filename=f'graphs/causality_graphs/{age_group[AG_index]}_ml.png')\n",
    "# # Save to pickle file.\n",
    "# theMatrix_ml = np.array(theMatrix_ml)\n",
    "# with open('./data/graph/ml_adj_mat.pkl', 'wb') as f:\n",
    "#     pickle.dump([[], [], theMatrix_gran], f, protocol=2)\n",
    "\n",
    "\n",
    "# COMPARISON MATRIX\n",
    "#comparison_db = create_comparison_database(theMatrix_gran, theMatrix_te, theMatrix_ml)\n",
    "#print(comparison_db)\n",
    "#with open(f'{age_group[AG_index]}_comparison.txt', 'w', encoding=\"utf-8\") as f:\n",
    "#  f.write(comparison_db)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DCRNN Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dcrnn():\n",
    "    with open('./data/model/dcrnn_covid.yaml') as f:\n",
    "        supervisor_config = yaml.load(f,Loader=yaml.Loader)\n",
    "\n",
    "        graph_pkl_filename = supervisor_config['data'].get('graph_pkl_filename')\n",
    "        sensor_ids, sensor_id_to_ind, adj_mx = load_graph_data(graph_pkl_filename)\n",
    "\n",
    "        supervisor = DCRNNSupervisor(adj_mx=adj_mx, **supervisor_config)\n",
    "\n",
    "        supervisor.train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dcrnn()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8d41b7f97a7d3802dbaafaf8b366829b7a45cccd34f80ad3826526d1dab4390b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
